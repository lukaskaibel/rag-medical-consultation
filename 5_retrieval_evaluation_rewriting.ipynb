{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcd96e4",
   "metadata": {},
   "source": [
    "# Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ee93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"haystack-ai>=2.15.0rc1\"\n",
    "# %pip install ragas-haystack\n",
    "# %pip install nltk\n",
    "# %pip install openai\n",
    "# %pip install pandas\n",
    "# %pip install ragas-haystack\n",
    "# %pip install \"sentence-transformers>=3.0.0\"\n",
    "# %pip install hf_xet\n",
    "# %pip install \"ollama-haystack==2.4.2\"\n",
    "# %pip install tqdm # For Progress Bar\n",
    "# %pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef9a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.dataclasses import ChatMessage\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import logging\n",
    "from pipelines.evaluation.base_retrieval_eval_pipeline import get_base_retrieval_eval_pipeline\n",
    "from models import EmbeddingModelConfig, EmbeddingModelProvider, LLMConfig, LLMProvider, RewriterModelConfig\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(asctime)s %(levelname)s %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logging.getLogger(\"haystack\").setLevel(logging.WARNING)\n",
    "\n",
    "os.environ[\"SENTENCE_TRANSFORMERS_HOME\"] = \"./model-assets/sentence-transformers\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"./model-assets/hugging-face\"\n",
    "os.environ[\"LLM_CONTEXT_SIZE\"] = \"40000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25347f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_TOP_K = 10 # Number of documents returned at the end of pipeline\n",
    "NUMBER_OF_QUESTIONS_IN_EVAL = 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76acf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_configs = [\n",
    "    {\n",
    "        \"name\": \"No Rewriting\",\n",
    "        \"embedding_model\": EmbeddingModelConfig(name=\"Qwen/Qwen3-Embedding-8B\", provider=EmbeddingModelProvider.SENTENCE_TRANSFORMER),\n",
    "        \"reranking_model\": None,\n",
    "        \"contextualizer_model\": None,\n",
    "        \"rewriter_model\": None,\n",
    "        \"retrieval-top-k\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Rewriting Zero Shot\",\n",
    "        \"embedding_model\": EmbeddingModelConfig(name=\"Qwen/Qwen3-Embedding-8B\", provider=EmbeddingModelProvider.SENTENCE_TRANSFORMER),\n",
    "        \"reranking_model\": None,\n",
    "        \"contextualizer_model\": None,\n",
    "        \"rewriter_model\": RewriterModelConfig(\n",
    "            LLMConfig(name=\"gemma3:27b\", provider=LLMProvider.OLLAMA),\n",
    "            \"\"\"You are a helpful assistant that rewrites a user's question for a RAG system. \n",
    "            Keep the original meaning and language. Strip out filler words and irrelevant context, preserve all named entities and technical terms, and enrich phrasing with clearer structure or synonyms. \n",
    "            If prior messages are provided, include only the essential details from them to ensure the question is fully self-contained. \n",
    "            Output only the rewritten question—no additional text.\n",
    "            \"\"\"     \n",
    "        ),\n",
    "        \"retrieval-top-k\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Rewriting Few Shot\",\n",
    "        \"embedding_model\": EmbeddingModelConfig(name=\"Qwen/Qwen3-Embedding-8B\", provider=EmbeddingModelProvider.SENTENCE_TRANSFORMER),\n",
    "        \"reranking_model\": None,\n",
    "        \"contextualizer_model\": None,\n",
    "        \"rewriter_model\": RewriterModelConfig(\n",
    "            LLMConfig(name=\"gemma3:27b\", provider=LLMProvider.OLLAMA),\n",
    "            \"\"\"You are a helpful assistant that rewrites a user's question for a RAG system. \n",
    "            Keep the original meaning and language. Strip out filler words and irrelevant context, preserve all named entities and technical terms, and enrich phrasing with clearer structure or synonyms. \n",
    "            If prior messages are provided, include only the essential details from them to ensure the question is fully self-contained. \n",
    "            Output only the rewritten question—no additional text.\n",
    "\n",
    "            Example 1\n",
    "            Original: “Um, like, what medication should I take for my morning headaches? I've been getting them almost every day.”\n",
    "            Rewritten: Which medication is most effective for treating daily morning headaches?\n",
    "\n",
    "            Example 2\n",
    "            Original: “Hey, I'm confused—what's the normal blood pressure range for adults? I've seen different numbers online.”\n",
    "            Rewritten: What is the normal adult blood pressure range?\n",
    "            \"\"\"     \n",
    "        ),\n",
    "        \"retrieval-top-k\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"HyDE Zero Shot\",\n",
    "        \"embedding_model\": EmbeddingModelConfig(name=\"Qwen/Qwen3-Embedding-8B\", provider=EmbeddingModelProvider.SENTENCE_TRANSFORMER),\n",
    "        \"reranking_model\": None,\n",
    "        \"contextualizer_model\": None,\n",
    "        \"rewriter_model\": RewriterModelConfig(\n",
    "            LLMConfig(name=\"gemma3:27b\", provider=LLMProvider.OLLAMA),\n",
    "            \"\"\"You are a helpful assistant that, given a user’s medical question and any prior conversation context, produces a single concise paragraph addressing that question. \n",
    "            Keep the original meaning and language; strip out filler words and irrelevant context; preserve all named entities and technical terms; enrich phrasing with clearer structure or synonyms; and incorporate necessary context from previous messages only when essential. \n",
    "            Output only the paragraph—no additional text.\n",
    "            \"\"\"     \n",
    "        ),\n",
    "        \"retrieval-top-k\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"HyDE Few Shot\",\n",
    "        \"embedding_model\": EmbeddingModelConfig(name=\"Qwen/Qwen3-Embedding-8B\", provider=EmbeddingModelProvider.SENTENCE_TRANSFORMER),\n",
    "        \"reranking_model\": None,\n",
    "        \"contextualizer_model\": None,\n",
    "        \"rewriter_model\": RewriterModelConfig(\n",
    "            LLMConfig(name=\"gemma3:27b\", provider=LLMProvider.OLLAMA),\n",
    "            \"\"\"You are a helpful assistant that, given a user’s medical question and any prior conversation context, produces a single concise paragraph addressing that question. \n",
    "            Keep the original meaning and language; strip out filler words and irrelevant context; preserve all named entities and technical terms; enrich phrasing with clearer structure or synonyms; and incorporate necessary context from previous messages only when essential. \n",
    "            Output only the paragraph—no additional text.\n",
    "\n",
    "            Example 1\n",
    "            Original: “Um, like, what medication should I take for my morning headaches? I’ve been getting them almost every day.”\n",
    "            Paragraph: Daily morning headaches warrant evaluation of underlying etiologies such as tension-type or migraine; first-line management typically includes NSAIDs (e.g., ibuprofen 400 mg with breakfast) or acetaminophen if NSAIDs are contraindicated, with migraine-specific options like sumatriptan 50 mg at headache onset and preventive therapy (e.g., topiramate 25 mg daily) for frequent episodes, alongside nonpharmacologic measures such as optimizing sleep hygiene and stress reduction.\n",
    "\n",
    "            Example 2\n",
    "            Original: “Hey, I'm confused—what’s the normal blood pressure range for adults? I’ve seen different numbers online.”\n",
    "            Paragraph: Normal adult blood pressure is defined as systolic < 120 mm Hg and diastolic < 80 mm Hg, while elevated levels (120–129/< 80) and stage 1 hypertension (130–139/80–89) reflect updated American Heart Association criteria, contrasted with European guidelines that consider values < 130/85 mm Hg as normal, informing clinical decisions on lifestyle modification and pharmacotherapy thresholds.\n",
    "            \"\"\"     \n",
    "        ),\n",
    "        \"retrieval-top-k\": 10,\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575791fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/600 [00:00<?, ?row/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecea512dd8c40ef94a67b51955572f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/600 [00:32<?, ?row/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 23.68 GiB of which 4.69 MiB is free. Process 407681 has 16.83 GiB memory in use. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.58 GiB is allocated by PyTorch, and 62.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m             df.to_pickle(save_path)\n\u001b[32m     84\u001b[39m df = pd.read_pickle(\u001b[33m\"\u001b[39m\u001b[33mdata/qa_with_docs_flat/question_answers_docs_word_100_20_dataset_flat.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mrun_retrieval_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion_answers_docs_word_100_20_dataset_flat.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mrun_retrieval_eval\u001b[39m\u001b[34m(filename, df)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m test_config \u001b[38;5;129;01min\u001b[39;00m test_configs:\n\u001b[32m     30\u001b[39m     base_indexing_store = InMemoryDocumentStore.load_from_disk(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/document_stores/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_config[\u001b[33m'\u001b[39m\u001b[33membedding_model\u001b[39m\u001b[33m'\u001b[39m].name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/base/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplitting_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_indexing_store.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     pipeline = \u001b[43mget_base_retrieval_eval_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_indexing_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_indexing_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_model_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membedding_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreranking_model_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreranking_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrewriting_model_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrewriter_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     request_payload = {\n\u001b[32m     38\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mretriever\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     39\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: test_config[\u001b[33m\"\u001b[39m\u001b[33mretrieval-top-k\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         }\n\u001b[32m     50\u001b[39m     }\n\u001b[32m     51\u001b[39m     previous_messages = [\n\u001b[32m     52\u001b[39m         ChatMessage.from_user(msg) \u001b[38;5;28;01mif\u001b[39;00m idx == \u001b[32m0\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m ChatMessage.from_assistant(msg)\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mprev_messages\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     55\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/pipelines/evaluation/base_retrieval_eval_pipeline.py:14\u001b[39m, in \u001b[36mget_base_retrieval_eval_pipeline\u001b[39m\u001b[34m(base_indexing_store, embedding_model_config, reranking_model_config, rewriting_model_config)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_base_retrieval_eval_pipeline\u001b[39m(\n\u001b[32m      9\u001b[39m     base_indexing_store: InMemoryDocumentStore,\n\u001b[32m     10\u001b[39m     embedding_model_config: EmbeddingModelConfig,\n\u001b[32m     11\u001b[39m     reranking_model_config: RerankingModelConfig,\n\u001b[32m     12\u001b[39m     rewriting_model_config: RewriterModelConfig,\n\u001b[32m     13\u001b[39m ) -> Pipeline:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     base_retrieval_pipeline = \u001b[43mpipelines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieval_pipelines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_retrieval_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_base_retrieval_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_indexing_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreranking_model_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewriting_model_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     map_evaluator = DocumentMAPEvaluator()\n\u001b[32m     17\u001b[39m     mrr_evaluator = DocumentMRREvaluator()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/pipelines/retrieval_pipelines/base_retrieval_pipeline.py:29\u001b[39m, in \u001b[36mget_base_retrieval_pipeline\u001b[39m\u001b[34m(document_store, embedding_model_config, reranking_model_config, rewriter_model_config)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_model_config.provider == EmbeddingModelProvider.SENTENCE_TRANSFORMER:\n\u001b[32m     23\u001b[39m     query_embedder = SentenceTransformersTextEmbedder(\n\u001b[32m     24\u001b[39m         model=embedding_model_config.name,\n\u001b[32m     25\u001b[39m         prefix=\u001b[33m\"\u001b[39m\u001b[33mInstruct: Given a question, retrieve relevant passages that answer the question\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuestion:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m         device=ComponentDevice.from_single(Device.gpu(\u001b[38;5;28mid\u001b[39m=\u001b[32m1\u001b[39m)),\n\u001b[32m     27\u001b[39m         model_kwargs={\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mfloat16\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     28\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mquery_embedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwarm_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m embedding_model_config.provider == EmbeddingModelProvider.OPENAI:\n\u001b[32m     31\u001b[39m     query_embedder = OpenAITextEmbedder(\n\u001b[32m     32\u001b[39m         model=embedding_model_config.name\n\u001b[32m     33\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/haystack/components/embedders/sentence_transformers_text_embedder.py:192\u001b[39m, in \u001b[36mSentenceTransformersTextEmbedder.warm_up\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mInitializes the component.\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embedding_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28mself\u001b[39m.embedding_backend = \u001b[43m_SentenceTransformersEmbeddingBackendFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_embedding_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_torch_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tokenizer_kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tokenizer_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28mself\u001b[39m.embedding_backend.model.max_seq_length = \u001b[38;5;28mself\u001b[39m.tokenizer_kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:38\u001b[39m, in \u001b[36m_SentenceTransformersEmbeddingBackendFactory.get_embedding_backend\u001b[39m\u001b[34m(model, device, auth_token, trust_remote_code, local_files_only, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, backend)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_backend_id \u001b[38;5;129;01min\u001b[39;00m _SentenceTransformersEmbeddingBackendFactory._instances:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _SentenceTransformersEmbeddingBackendFactory._instances[embedding_backend_id]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m embedding_backend = \u001b[43m_SentenceTransformersEmbeddingBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m _SentenceTransformersEmbeddingBackendFactory._instances[embedding_backend_id] = embedding_backend\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embedding_backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:74\u001b[39m, in \u001b[36m_SentenceTransformersEmbeddingBackend.__init__\u001b[39m\u001b[34m(self, model, device, auth_token, trust_remote_code, local_files_only, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, backend)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=too-many-positional-arguments\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     61\u001b[39m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m     backend: Literal[\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mopenvino\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m ):\n\u001b[32m     72\u001b[39m     sentence_transformers_import.check()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:348\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28mself\u001b[39m.is_hpu_graph_enabled = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 915 (3 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/data/pia-rag-eval/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 23.68 GiB of which 4.69 MiB is free. Process 407681 has 16.83 GiB memory in use. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.58 GiB is allocated by PyTorch, and 62.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "def run_retrieval_eval(filename, df):\n",
    "    import config.prompt\n",
    "    importlib.reload(config.prompt)\n",
    "\n",
    "    import re\n",
    "\n",
    "    match = re.search(r\"answers_(.*?)_dataset\", filename)\n",
    "    if match:\n",
    "        splitting_strategy = match.group(1)\n",
    "    else:\n",
    "        splitting_strategy = None\n",
    "\n",
    "    # 1) Filter out the null‐question rows\n",
    "    df_nonnull = df[df[\"question\"].notnull()]\n",
    "\n",
    "    df_shuffled = df_nonnull.sample(n=NUMBER_OF_QUESTIONS_IN_EVAL, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    for index, row in tqdm(\n",
    "        df_shuffled.iterrows(),\n",
    "        total=len(df_shuffled),\n",
    "        desc=\"Processing rows\",\n",
    "        unit=\"row\"\n",
    "    ):\n",
    "        relevant_documents = row[\"documents\"]\n",
    "        question = row[\"question\"]\n",
    "\n",
    "        for test_config in test_configs:\n",
    "            base_indexing_store = InMemoryDocumentStore.load_from_disk(f\"data/document_stores/{test_config['embedding_model'].name}/base/{splitting_strategy}_indexing_store.json\")\n",
    "            pipeline = get_base_retrieval_eval_pipeline(\n",
    "                base_indexing_store=base_indexing_store,\n",
    "                embedding_model_config=test_config[\"embedding_model\"],\n",
    "                reranking_model_config=test_config[\"reranking_model\"],\n",
    "                rewriting_model_config=test_config[\"rewriter_model\"],\n",
    "            )\n",
    "            request_payload = {\n",
    "                \"retriever\": {\n",
    "                    \"top_k\": test_config[\"retrieval-top-k\"],\n",
    "                },\n",
    "                \"map_evaluator\": {\n",
    "                    \"ground_truth_documents\": [relevant_documents],\n",
    "                },\n",
    "                \"mrr_evaluator\": {\n",
    "                    \"ground_truth_documents\": [relevant_documents],\n",
    "                },\n",
    "                \"recall_evaluator\": {\n",
    "                    \"ground_truth_documents\": [relevant_documents],\n",
    "                }\n",
    "            }\n",
    "            previous_messages = [\n",
    "                ChatMessage.from_user(msg) if idx == 0\n",
    "                else ChatMessage.from_assistant(msg)\n",
    "                for idx, msg in enumerate(row[\"prev_messages\"])\n",
    "            ]\n",
    "            if \"rewriter\" in pipeline.graph.nodes:\n",
    "                request_payload[\"rewriter\"] = {\n",
    "                    \"query\": question,\n",
    "                    \"previous_messages\": previous_messages,\n",
    "                }\n",
    "            else:\n",
    "                request_payload[\"query_embedder\"] = {\n",
    "                    \"text\": question,\n",
    "                }\n",
    "            if \"reranker\" in pipeline.graph.nodes:\n",
    "                request_payload[\"reranker\"] = {\n",
    "                    \"query\": question,\n",
    "                    \"top_k\": FINAL_TOP_K,\n",
    "                }\n",
    "            result = pipeline.run(request_payload)\n",
    "\n",
    "            map_score = result.get(\"map_evaluator\", {}).get(\"score\", {})\n",
    "            mrr_score = result.get(\"mrr_evaluator\", {}).get(\"score\", {})\n",
    "            recall_score = result.get(\"recall_evaluator\", {}).get(\"score\", {})\n",
    "\n",
    "            df.at[index, f\"{test_config['name']}_map\"] = map_score\n",
    "            df.at[index, f\"{test_config['name']}_mrr\"] = mrr_score\n",
    "            df.at[index, f\"{test_config['name']}_recall\"] = recall_score\n",
    "\n",
    "            save_path = f\"results/retrieval/rewriter/{now.strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            df.to_pickle(save_path)\n",
    "\n",
    "df = pd.read_pickle(\"data/qa_with_docs_flat/question_answers_docs_word_100_20_dataset_flat.pkl\")\n",
    "run_retrieval_eval(\"question_answers_docs_word_100_20_dataset_flat.pkl\", df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c56c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>references</th>\n",
       "      <th>groundTruth</th>\n",
       "      <th>source_file</th>\n",
       "      <th>variations_pretty</th>\n",
       "      <th>documents</th>\n",
       "      <th>variant</th>\n",
       "      <th>prev_messages</th>\n",
       "      <th>No Rewriting_map</th>\n",
       "      <th>No Rewriting_mrr</th>\n",
       "      <th>...</th>\n",
       "      <th>Rewriting Zero Shot_recall</th>\n",
       "      <th>Rewriting Few Shot_map</th>\n",
       "      <th>Rewriting Few Shot_mrr</th>\n",
       "      <th>Rewriting Few Shot_recall</th>\n",
       "      <th>HyDE Zero Shot_map</th>\n",
       "      <th>HyDE Zero Shot_mrr</th>\n",
       "      <th>HyDE Zero Shot_recall</th>\n",
       "      <th>HyDE Few Shot_map</th>\n",
       "      <th>HyDE Few Shot_mrr</th>\n",
       "      <th>HyDE Few Shot_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wie läuft eine äußere Wendung genau ab und was...</td>\n",
       "      <td>[Eine äußere Wendung findet in der Regel in ei...</td>\n",
       "      <td>Eine äußere Wendung findet ambulant in einer K...</td>\n",
       "      <td>Äußere Wendung.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=6574586c437e0711c9ac7d01e25f91424...</td>\n",
       "      <td>default</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und was passiert dann genau davor?</td>\n",
       "      <td>[Eine äußere Wendung findet in der Regel in ei...</td>\n",
       "      <td>Eine äußere Wendung findet ambulant in einer K...</td>\n",
       "      <td>Äußere Wendung.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=6574586c437e0711c9ac7d01e25f91424...</td>\n",
       "      <td>contextual</td>\n",
       "      <td>[Ich habe von der äußeren Wendung gehört, könn...</td>\n",
       "      <td>0.18254</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie genau läuft so ne äußere Wendung ab und wa...</td>\n",
       "      <td>[Eine äußere Wendung findet in der Regel in ei...</td>\n",
       "      <td>Eine äußere Wendung findet ambulant in einer K...</td>\n",
       "      <td>Äußere Wendung.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=6574586c437e0711c9ac7d01e25f91424...</td>\n",
       "      <td>slang</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is an external version performed exactly a...</td>\n",
       "      <td>[Eine äußere Wendung findet in der Regel in ei...</td>\n",
       "      <td>Eine äußere Wendung findet ambulant in einer K...</td>\n",
       "      <td>Äußere Wendung.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=6574586c437e0711c9ac7d01e25f91424...</td>\n",
       "      <td>english</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>äußere Wendung Ablauf Vorbereitung</td>\n",
       "      <td>[Eine äußere Wendung findet in der Regel in ei...</td>\n",
       "      <td>Eine äußere Wendung findet ambulant in einer K...</td>\n",
       "      <td>Äußere Wendung.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=6574586c437e0711c9ac7d01e25f91424...</td>\n",
       "      <td>keyword</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Risiken Ballonkatheter?</td>\n",
       "      <td>[Die Einlage und das Befüllen der Ballons könn...</td>\n",
       "      <td>Bei der Anwendung eines Ballonkatheters kann d...</td>\n",
       "      <td>Einleitung der Geburt.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...</td>\n",
       "      <td>short</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Ich möchte wissen, welche möglichen Komplikati...</td>\n",
       "      <td>[Die Einlage und das Befüllen der Ballons könn...</td>\n",
       "      <td>Bei der Anwendung eines Ballonkatheters kann d...</td>\n",
       "      <td>Einleitung der Geburt.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...</td>\n",
       "      <td>long</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Welche potenziellen Komplikationen und Risiken...</td>\n",
       "      <td>[Die Einlage und das Befüllen der Ballons könn...</td>\n",
       "      <td>Bei der Anwendung eines Ballonkatheters kann d...</td>\n",
       "      <td>Einleitung der Geburt.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Welche Risiken gibt es bei der Anwendung eines...</td>\n",
       "      <td>[Die Einlage und das Befüllen der Ballons könn...</td>\n",
       "      <td>Bei der Anwendung eines Ballonkatheters kann d...</td>\n",
       "      <td>Einleitung der Geburt.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...</td>\n",
       "      <td>mistake</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Doğum başlatmak için balon kateter kullanmanın...</td>\n",
       "      <td>[Die Einlage und das Befüllen der Ballons könn...</td>\n",
       "      <td>Bei der Anwendung eines Ballonkatheters kann d...</td>\n",
       "      <td>Einleitung der Geburt.md</td>\n",
       "      <td>\"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...</td>\n",
       "      <td>[Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...</td>\n",
       "      <td>turkish</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Wie läuft eine äußere Wendung genau ab und was...   \n",
       "1                   Und was passiert dann genau davor?   \n",
       "2    Wie genau läuft so ne äußere Wendung ab und wa...   \n",
       "3    How is an external version performed exactly a...   \n",
       "4                   äußere Wendung Ablauf Vorbereitung   \n",
       "..                                                 ...   \n",
       "605                            Risiken Ballonkatheter?   \n",
       "606  Ich möchte wissen, welche möglichen Komplikati...   \n",
       "607  Welche potenziellen Komplikationen und Risiken...   \n",
       "608  Welche Risiken gibt es bei der Anwendung eines...   \n",
       "609  Doğum başlatmak için balon kateter kullanmanın...   \n",
       "\n",
       "                                            references  \\\n",
       "0    [Eine äußere Wendung findet in der Regel in ei...   \n",
       "1    [Eine äußere Wendung findet in der Regel in ei...   \n",
       "2    [Eine äußere Wendung findet in der Regel in ei...   \n",
       "3    [Eine äußere Wendung findet in der Regel in ei...   \n",
       "4    [Eine äußere Wendung findet in der Regel in ei...   \n",
       "..                                                 ...   \n",
       "605  [Die Einlage und das Befüllen der Ballons könn...   \n",
       "606  [Die Einlage und das Befüllen der Ballons könn...   \n",
       "607  [Die Einlage und das Befüllen der Ballons könn...   \n",
       "608  [Die Einlage und das Befüllen der Ballons könn...   \n",
       "609  [Die Einlage und das Befüllen der Ballons könn...   \n",
       "\n",
       "                                           groundTruth  \\\n",
       "0    Eine äußere Wendung findet ambulant in einer K...   \n",
       "1    Eine äußere Wendung findet ambulant in einer K...   \n",
       "2    Eine äußere Wendung findet ambulant in einer K...   \n",
       "3    Eine äußere Wendung findet ambulant in einer K...   \n",
       "4    Eine äußere Wendung findet ambulant in einer K...   \n",
       "..                                                 ...   \n",
       "605  Bei der Anwendung eines Ballonkatheters kann d...   \n",
       "606  Bei der Anwendung eines Ballonkatheters kann d...   \n",
       "607  Bei der Anwendung eines Ballonkatheters kann d...   \n",
       "608  Bei der Anwendung eines Ballonkatheters kann d...   \n",
       "609  Bei der Anwendung eines Ballonkatheters kann d...   \n",
       "\n",
       "                  source_file  \\\n",
       "0          Äußere Wendung.md   \n",
       "1          Äußere Wendung.md   \n",
       "2          Äußere Wendung.md   \n",
       "3          Äußere Wendung.md   \n",
       "4          Äußere Wendung.md   \n",
       "..                        ...   \n",
       "605  Einleitung der Geburt.md   \n",
       "606  Einleitung der Geburt.md   \n",
       "607  Einleitung der Geburt.md   \n",
       "608  Einleitung der Geburt.md   \n",
       "609  Einleitung der Geburt.md   \n",
       "\n",
       "                                     variations_pretty  \\\n",
       "0    \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "1    \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "2    \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "3    \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "4    \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "..                                                 ...   \n",
       "605  \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "606  \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "607  \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "608  \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "609  \"{\\\"contextual\\\": [{\\\"role\\\": \\\"user\\\", \\\"mess...   \n",
       "\n",
       "                                             documents     variant  \\\n",
       "0    [Document(id=6574586c437e0711c9ac7d01e25f91424...     default   \n",
       "1    [Document(id=6574586c437e0711c9ac7d01e25f91424...  contextual   \n",
       "2    [Document(id=6574586c437e0711c9ac7d01e25f91424...       slang   \n",
       "3    [Document(id=6574586c437e0711c9ac7d01e25f91424...     english   \n",
       "4    [Document(id=6574586c437e0711c9ac7d01e25f91424...     keyword   \n",
       "..                                                 ...         ...   \n",
       "605  [Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...       short   \n",
       "606  [Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...        long   \n",
       "607  [Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...   technical   \n",
       "608  [Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...     mistake   \n",
       "609  [Document(id=b92aa18d221df9e8cbef44cd1db9e8a52...     turkish   \n",
       "\n",
       "                                         prev_messages  No Rewriting_map  \\\n",
       "0                                                   []           1.00000   \n",
       "1    [Ich habe von der äußeren Wendung gehört, könn...           0.18254   \n",
       "2                                                   []           1.00000   \n",
       "3                                                   []           0.50000   \n",
       "4                                                   []           0.12500   \n",
       "..                                                 ...               ...   \n",
       "605                                                 []               NaN   \n",
       "606                                                 []               NaN   \n",
       "607                                                 []               NaN   \n",
       "608                                                 []               NaN   \n",
       "609                                                 []               NaN   \n",
       "\n",
       "     No Rewriting_mrr  ...  Rewriting Zero Shot_recall  \\\n",
       "0            1.000000  ...                         1.0   \n",
       "1            0.142857  ...                         1.0   \n",
       "2            1.000000  ...                         1.0   \n",
       "3            0.500000  ...                         1.0   \n",
       "4            0.125000  ...                         1.0   \n",
       "..                ...  ...                         ...   \n",
       "605               NaN  ...                         NaN   \n",
       "606               NaN  ...                         NaN   \n",
       "607               NaN  ...                         NaN   \n",
       "608               NaN  ...                         NaN   \n",
       "609               NaN  ...                         NaN   \n",
       "\n",
       "     Rewriting Few Shot_map  Rewriting Few Shot_mrr  \\\n",
       "0                  0.500000                0.500000   \n",
       "1                  0.111111                0.111111   \n",
       "2                  1.000000                1.000000   \n",
       "3                  0.583333                0.500000   \n",
       "4                  0.125000                0.125000   \n",
       "..                      ...                     ...   \n",
       "605                     NaN                     NaN   \n",
       "606                     NaN                     NaN   \n",
       "607                     NaN                     NaN   \n",
       "608                     NaN                     NaN   \n",
       "609                     NaN                     NaN   \n",
       "\n",
       "     Rewriting Few Shot_recall  HyDE Zero Shot_map  HyDE Zero Shot_mrr  \\\n",
       "0                          1.0            1.000000            1.000000   \n",
       "1                          1.0            0.238889            0.166667   \n",
       "2                          1.0            0.583333            0.500000   \n",
       "3                          1.0            0.500000            0.500000   \n",
       "4                          1.0            0.500000            0.500000   \n",
       "..                         ...                 ...                 ...   \n",
       "605                        NaN                 NaN                 NaN   \n",
       "606                        NaN                 NaN                 NaN   \n",
       "607                        NaN                 NaN                 NaN   \n",
       "608                        NaN                 NaN                 NaN   \n",
       "609                        NaN                 NaN                 NaN   \n",
       "\n",
       "     HyDE Zero Shot_recall  HyDE Few Shot_map  HyDE Few Shot_mrr  \\\n",
       "0                      1.0           0.333333           0.333333   \n",
       "1                      1.0           0.500000           0.500000   \n",
       "2                      1.0           1.000000           1.000000   \n",
       "3                      1.0           0.500000           0.500000   \n",
       "4                      1.0           0.111111           0.111111   \n",
       "..                     ...                ...                ...   \n",
       "605                    NaN                NaN                NaN   \n",
       "606                    NaN                NaN                NaN   \n",
       "607                    NaN                NaN                NaN   \n",
       "608                    NaN                NaN                NaN   \n",
       "609                    NaN                NaN                NaN   \n",
       "\n",
       "     HyDE Few Shot_recall  \n",
       "0                     1.0  \n",
       "1                     1.0  \n",
       "2                     1.0  \n",
       "3                     1.0  \n",
       "4                     1.0  \n",
       "..                    ...  \n",
       "605                   NaN  \n",
       "606                   NaN  \n",
       "607                   NaN  \n",
       "608                   NaN  \n",
       "609                   NaN  \n",
       "\n",
       "[610 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd3c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
